{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60d2722",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Categorización de publicaciones de productos de Mercado Libre\n",
    "Autores: Maximiliano Tejerina, Eduardo Barseghian, Benjamín Ocampo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6985297",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Otra método de exploración de caracteristicas es mediante técnicas de\n",
    "aprendizaje no supervisado siendo útil para comprender aún mejor el conjunto\n",
    "de datos con el que se dispone y mejorar la etapa de clasificación con esta\n",
    "información.\n",
    "\n",
    "En particular, en esta notebook se trabajó sobre técnicas de *clustering* a\n",
    "partir de la codificación de los títulos obtenida por los embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f8b0a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Imports y funciones *helper* necesarias\n",
    "Nuevamente se hizo uso del conjunto de datos remoto que se trabajó en\n",
    "distintas secciones de este repositorio. En particular aquel que tuvo los\n",
    "títulos ya preprocesados. En caso de querer conocer más como se realizó esta\n",
    "etapa se explicaron a detalle en el directorio `encoding/`.\n",
    "\n",
    "A su vez, se utilizó una muestra de 20000 ejemplares del conjunto de datos\n",
    "para facilitar el desarrollo y la explicación de este trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060513bb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import SilhouetteVisualizer, KElbowVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72484efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.famaf.unc.edu.ar/~nocampo043/ML_2019_challenge_dataset_preprocessed.csv\"\n",
    "NOF_SAMPLES = 20000\n",
    "SEED = 0\n",
    "\n",
    "def unsupervised_data_gen(sentences, corpus_file):\n",
    "    with open(corpus_file, \"w\") as out:\n",
    "        for s in sentences:\n",
    "            out.write(s + \"\\n\")\n",
    "\n",
    "def get_word_embedding(vocab, vectorize):\n",
    "    return (\n",
    "        pd.DataFrame({word: vectorize(word) for word in vocab})\n",
    "        .transpose()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"word\"})\n",
    "    )\n",
    "\n",
    "def get_word_embedding_2DTSNE(vocab, model):\n",
    "    embedding = get_word_embedding(vocab, model)\n",
    "    X = embedding.drop(columns=[\"word\"])\n",
    "    X_TSNE = TSNE(n_components=2).fit_transform(X)\n",
    "    embedding_TSNE = pd.concat(\n",
    "        [pd.DataFrame(vocab, columns=[\"word\"]),\n",
    "         pd.DataFrame(X_TSNE)], axis=1)\n",
    "    return embedding_TSNE\n",
    "\n",
    "def get_sentence_embedding(sentences, vectorize):\n",
    "    return (\n",
    "        pd.DataFrame({s: vectorize(s) for s in sentences})\n",
    "        .transpose()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"sentence\"})\n",
    "    )\n",
    "\n",
    "def get_sentence_embedding_2DTSNE(sentences, vectorize):\n",
    "    embedding = get_sentence_embedding(sentences, vectorize)\n",
    "    X = embedding.drop(columns=[\"sentence\"])\n",
    "    X_TSNE = TSNE(n_components=2).fit_transform(X)\n",
    "    embedding_TSNE = pd.concat(\n",
    "        [pd.DataFrame(sentences, columns=[\"sentence\"]),\n",
    "         pd.DataFrame(X_TSNE)], axis=1)\n",
    "    return embedding_TSNE\n",
    "\n",
    "\n",
    "def plot_2DTSNE(X_TSNE,\n",
    "                expressions,\n",
    "                ax,\n",
    "                point_size=50,\n",
    "                legend_size=20,\n",
    "                tick_size=20,\n",
    "                annotation_size=20,\n",
    "                annotate=True):\n",
    "    nof_words = len(X_TSNE)\n",
    "    ax.scatter(X_TSNE[:, 0],\n",
    "               X_TSNE[:, 1],\n",
    "               s=point_size)\n",
    "    ax.set_title(\"t-SNE Plot\", fontsize=legend_size)\n",
    "    annot_list = []\n",
    "\n",
    "    if annotate:\n",
    "        nof_words_to_annotate = 20\n",
    "        for i in np.random.randint(nof_words, size=nof_words_to_annotate):\n",
    "            a = ax.annotate(expressions[i], (X_TSNE[i, 0], X_TSNE[i, 1]),\n",
    "                            size=annotation_size)\n",
    "            annot_list.append(a)\n",
    "        adjust_text(annot_list)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_size)\n",
    "\n",
    "\n",
    "def plot_2D_kmeans(X_TSNE,\n",
    "                   km_model,\n",
    "                   ax,\n",
    "                   marker_size=2,\n",
    "                   legend_size=20,\n",
    "                   tick_size=20):\n",
    "    cluster_df = pd.DataFrame(X_TSNE)\n",
    "    cluster_df = cluster_df.assign(label=km_model.labels_)\n",
    "    sns.scatterplot(data=cluster_df, x=0, y=1, hue=\"label\", palette=\"tab20\", ax=ax)\n",
    "    ax.legend(bbox_to_anchor=(1.02, 1.02),\n",
    "              loc='upper left',\n",
    "              markerscale=marker_size,\n",
    "              prop={\"size\": legend_size})\n",
    "    ax.set_title(\"KMeans Plot\", fontsize=legend_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_size)\n",
    "\n",
    "\n",
    "def plot_silhouette(X, km_model, ax, title_size=20, tick_size=20):\n",
    "    visualizer = SilhouetteVisualizer(km_model, colors='tab20', ax=ax)\n",
    "    visualizer.fit(X)\n",
    "    ax.set_title(\"Silhoutte Plot\", fontsize=title_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_size)\n",
    "\n",
    "def plot_elbow(X, estimator, metric, k_range, ax, title_size=10, tick_size=10):\n",
    "    visualizer = KElbowVisualizer(estimator(),\n",
    "                                  k=k_range,\n",
    "                                  metric=metric,\n",
    "                                  timings=False,\n",
    "                                  ax=ax)\n",
    "    visualizer.fit(X)\n",
    "    ax.set_title(\"Elbow Plot\", fontsize=title_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c2281",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(URL)\n",
    "df = df.sample(n=NOF_SAMPLES, random_state=SEED)\n",
    "df = df.drop_duplicates(subset=\"cleaned_title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f463bd16",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Inicialmente se proyectó la columna `cleaned_title` con los títulos de las\n",
    "publicaciones ya preprocesadas siendo esta el corpus que se trabajó.\n",
    "\n",
    "Algo a recalcar es que luego del preprocesamiento se dió el caso de tener\n",
    "algunas oraciones repetidas. Para evitar tener dos representaciones distintas\n",
    "de la misma oración se optó por eliminar los duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9895e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "sentences = df[\"cleaned_title\"].drop_duplicates().tolist()\n",
    "corpus_file = \"titles.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d35e87",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## FastText\n",
    "A diferencia del trabajo efectuado de clasificación y aprendizaje supervisado,\n",
    "se utilizó FastText como algoritmo para obtener un modelo del lenguaje de los\n",
    "títulos por medio de la API de Facebook. Se pudo haber utilizado `Gensim` pero\n",
    "solo nos permite realizar codificación a nivel de palabra. Dado que el\n",
    "objetivo de este trabajo es aplicar técnicas de *clustering* sobre oraciones,\n",
    "la codificación de estas debía implementarse para esta librería. No fue este\n",
    "el caso durante el modelo usado en clasificación ya que Keras se encargó de\n",
    "obtener la representación vectorial de los títulos al incluir el modelo de\n",
    "lenguaje de `Gensim` como una *embedding layer*.\n",
    "\n",
    "FastText para obtener la representación a nivel de palabra genera una tarea de\n",
    "pretexto a partir de las oraciones que se le dispone por medio de un archivo,\n",
    "en este caso `corpus_file`. Con ello se obtiene el modelo de lenguaje que se\n",
    "utilizó para realizar esta exploración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c7558",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "unsupervised_data_gen(sentences, corpus_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d9762",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model = fasttext.train_unsupervised(corpus_file,\n",
    "                                    model=\"cbow\",\n",
    "                                    lr=0.3,\n",
    "                                    epoch=100,\n",
    "                                    dim=100,\n",
    "                                    wordNgrams=4,\n",
    "                                    ws=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529b0a25",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Cada palabra en el vocabulario tiene una representación vectorial de dimensión\n",
    "`dim=100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7043d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07222626",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model.get_words()[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2052673b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "También como mostramos en otras notebooks de embeddings, la representación\n",
    "vectorial de las palabras `barbero` y `cafetera` está a una distancia cercana\n",
    "de otras con un significado similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a37519",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model.get_nearest_neighbors(\"barbero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f7c39",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model.get_nearest_neighbors(\"cafetera\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c1937",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Clustering a nivel de palabra\n",
    "A pesar de este no ser el objetivo se intentó mostrar como se disponen las\n",
    "palabras en el espacio por medio de TSNE para proyectar los embeddings a 2D.\n",
    "Sin embargo, se aplicó `KMeans` en el espacio de 100 dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06b106",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "vocab = model.get_words()\n",
    "embedding = get_word_embedding(vocab, model.get_word_vector)\n",
    "embedding_TSNE = get_word_embedding_2DTSNE(vocab, model.get_word_vector)\n",
    "X = embedding.drop(columns=[\"word\"]).to_numpy()\n",
    "X_TSNE = embedding_TSNE.drop(columns=[\"word\"]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00275c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6fe6d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "_, (ax_kmeans, ax_tsne) = plt.subplots(1, 2, figsize=(30, 10))\n",
    "plot_2DTSNE(X_TSNE, vocab, ax_tsne)\n",
    "plot_2D_kmeans(X_TSNE, kmeans, ax_kmeans)\n",
    "ax_kmeans.grid()\n",
    "ax_tsne.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8105c34",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "_, (ax_silhouette, ax_kmeans) = plt.subplots(1, 2, figsize=(30, 10))\n",
    "plot_silhouette(X, kmeans, ax_silhouette)\n",
    "plot_2D_kmeans(X_TSNE, kmeans, ax_kmeans)\n",
    "ax_silhouette.grid()\n",
    "ax_kmeans.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb845b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Sin embargo a pesar de los gráficos, no se alcanza a percibir agrupamientos a\n",
    "través de la representación con TSNE. Sin embargo, la cercania de los\n",
    "significados se mantiene. Se cree que la disposición de las palabras en el\n",
    "`blob` si ocurren. Por ejemplo que las palabras más relacionadas con\n",
    "`cafetera` se encuentran en el hemisferio izquierdo del `blob`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9041838e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Clustering a nivel de títulos\n",
    "Para esta sección se obtuvo el embedding de una oración tomando las\n",
    "representaciones individuales de cada palabra que la componen, dividiendo esos\n",
    "vectores por su norma y considerando el promedio de ellas. Esto realiza\n",
    "internamente FastText por medio de `get_sentence_vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e2b4d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "embedding = get_sentence_embedding(sentences, model.get_sentence_vector)\n",
    "embedding_TSNE = get_sentence_embedding_2DTSNE(sentences,\n",
    "                                               model.get_sentence_vector)\n",
    "X = embedding.drop(columns=[\"sentence\"]).to_numpy()\n",
    "X_TSNE = embedding_TSNE.drop(columns=[\"sentence\"]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388365dd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d8360f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "embedding_TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c3050",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Elbow Method\n",
    "Con el fin de seleccionar la cantidad óptima de clusters, una de las\n",
    "estrategias usadas fue el `Elbow Method` que consiste en seleccionar un rango\n",
    "de valores `k_range` ajustando el modelo de `KMeans`. Con ello confeccionamos\n",
    "un gráfico de linea de tal manera que, si este se asemeja al de un codo,\n",
    "entonces el punto de inflección de la curva es un buen indicador de cual es el\n",
    "mejor modelo. La métrica utilizada en este caso fue `distortion` que consiste\n",
    "en la suma de las distancias al cuadrado de cada punto al centro de los\n",
    "clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002cfd1d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "fig, ax_elbow = plt.subplots()\n",
    "k_range = (2, 20)\n",
    "plot_elbow(X, KMeans, \"distortion\", k_range, ax_elbow)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9319d6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Si bien no se encuentra ningun codo pronunciado, el algoritmo encuentra que la\n",
    "cantidad óptima es de 11 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086e57de",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=11)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b3cff6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Silhouette\n",
    "Una vez ajustado para la cantidad de clusters dada con el método anterior se\n",
    "utilizó el método de silhouette junto a una visualización de los clusters\n",
    "ajustada en las 100 dimensiones aproximada en 2D usando TSNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d1f9dc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "_, (ax_silhouette, ax_kmeans) = plt.subplots(1, 2, figsize=(30, 10))\n",
    "plot_silhouette(X, kmeans, ax_silhouette)\n",
    "plot_2D_kmeans(X_TSNE, kmeans, ax_kmeans)\n",
    "ax_silhouette.grid()\n",
    "ax_kmeans.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaa8a95",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Notar que el coeficiente de silhouette promedio de cada uno de los clusters es\n",
    "de aproximadamente 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49660ce9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Top 10 categorías más presentes en cada cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53cbf66",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df = df.assign(cluster=kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f504d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_cross = pd.crosstab(df[\"category\"], df[\"cluster\"])\n",
    "df_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40e1034",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "for cluster in df_cross:\n",
    "    print(df_cross[cluster].sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcfd0a1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Notar que para cada uno de los tops hay categorias que tienen una pequeña\n",
    "cantidad de ejemplares. Por lo tanto solo consideraremos aquellas que superen\n",
    "los 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c223607",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "for cluster in df_cross:\n",
    "    print(\n",
    "        df_cross\n",
    "        .loc[df_cross[cluster] > 100, cluster]\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d73d2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Solo algunos cluster se puede comentar que podrían llegar a tener alguna\n",
    "relación en cuanto a su significado. Tales son el caso de los clusters:\n",
    " 0: Relacionado a elementos de cocina.\n",
    " 2: Productos para bebé.\n",
    " 5: Ropa.\n",
    " 7 y 9: Nuevamente elementos de cocina y ropa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d752c57",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Porcentaje de títulos a cada cluster\n",
    "De manera similar podemos obtener, para cada categoría, el porcentaje de\n",
    "títulos que pertence a cada cluster. Obteniendo una representación similar a\n",
    "la anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f1474b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "df_cross_percent = pd.crosstab(df[\"category\"], df[\"cluster\"], normalize=\"index\")\n",
    "df_cross_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac36899a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "for cluster in df_cross_percent:\n",
    "    print(df_cross_percent[cluster].sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bb9097",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Nuevamente podemos optar por considerar solo aquellas categorías con un\n",
    "porcentaje superior a un umbral, en este caso a 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2bb113",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "for cluster in df_cross_percent:\n",
    "    print(\n",
    "        df_cross_percent\n",
    "        .loc[df_cross_percent[cluster] > 0.1, cluster]\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83fb759",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "Algunos desafios con los que nos encontramos es la posibilidad de utilizar el\n",
    "conjunto completo de datos para realizar los experimentos. Una posibilidad\n",
    "para mejorar el modelo de lenguaje obtenido sería utilizar todos los\n",
    "ejemplares en lugar de un sampleo.\n",
    "\n",
    "Los resultados obtenidos con los embeddings de FastText para los títulos\n",
    "tampoco fueron muy significativos para obtener alguna conclusión sólida de los\n",
    "agrupamientos. Una posiblidad podría ser probar distintos parámetros del\n",
    "modelo de lenguaje o utilizar otros métodos de vectorización (BOW, matriz\n",
    "de co-ocurrencia, triplas de dependencia, etc) de tal manera de poder\n",
    "compararlos."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
