{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Categorización de publicaciones de productos de Mercado Libre\n",
    "\n",
    " Autores: Maximiliano Tejerina, Eduardo Barseghian, Benjamín Ocampo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Reducción del dataset y definición de funciones *helper*\n",
    " Luego de realizar la reducción del dataset a un total de 20 categorías y\n",
    " 646760 publicaciones, es colocado disponible en un servidor permitiendo ser\n",
    " accedido por medio de una URL.\n",
    "\n",
    " Inicialmente se definen constantes y funciones que permiten obtener\n",
    " información cuantitativa de las publicaciones así como de su estructura. Por\n",
    " un lado, `count_stopwords`, `count_special_chars`, `count_digits`, permiten\n",
    " hacer conteos sobre la estructura de las publicaciones, cuando en contraparte\n",
    " `proportion` permite hacer una comparación entre cantidades de grupos de\n",
    " interés. También se definen nuestras variables aleatorias o columnas\n",
    " relevantes y un conjunto `stopwords` que almacena palabras como articulos, o\n",
    " proposiciones frecuentes del español y el portugués."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "\n",
    "URL = \"https://www.famaf.unc.edu.ar/~nocampo043/ml_challenge2019_dataset.csv\"\n",
    "df = pd.read_csv(URL)\n",
    "\n",
    "title = \"title\"\n",
    "category = \"category\"\n",
    "label_quality = \"label_quality\"\n",
    "language = \"language\"\n",
    "\n",
    "stopwords = \\\n",
    "    set(nltk.corpus.stopwords.words(\"spanish\")) | \\\n",
    "    set(nltk.corpus.stopwords.words(\"portuguese\"))\n",
    "\n",
    "def proportion(df, by, col):\n",
    "    df_proportion = df.groupby([by, col]) \\\n",
    "        .agg(count=(col, \"count\")) \\\n",
    "        .join(df.groupby(by).size().to_frame()) \\\n",
    "        .rename(columns={0: \"total\"})\n",
    "\n",
    "    df_proportion.loc[:, \"proportion\"] = df_proportion[\"count\"] / df_proportion[\"total\"]\n",
    "    return df_proportion\n",
    "\n",
    "def count_words(s):\n",
    "    return len(s.split())\n",
    "\n",
    "def count_stopwords(s):\n",
    "    return sum(\n",
    "        w.lower() in stopwords for w in word_tokenize(s)\n",
    "    )\n",
    "\n",
    "def count_special_chars(s):\n",
    "    word_freq = nltk.FreqDist(s)\n",
    "    special_chars = \"-.+,[@_!#$%^&*()<>?/\\|}{~:]\"\n",
    "    return sum(word_freq[sc] for sc in special_chars)\n",
    "\n",
    "def count_digits(s):\n",
    "    word_freq =  nltk.FreqDist(s)\n",
    "    digits = \"0123456789\"\n",
    "    return sum(word_freq[d] for d in digits)\n",
    "\n",
    "def remove_unimportant_words(s):\n",
    "    special_chars = \"-.+,[@_!#$%^&*()<>?/\\|}{~:]\"\n",
    "    digits = \"0123456789\"\n",
    "    invalid_chars = special_chars + digits\n",
    "\n",
    "    reduced_title = ''.join(c for c in s if not c in invalid_chars)\n",
    "\n",
    "    reduced_title = ' '.join(\n",
    "        w.lower() for w in word_tokenize(reduced_title)\n",
    "        if not w.lower() in stopwords\n",
    "    )\n",
    "    return reduced_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Exploración de publicaciones\n",
    " Como primera iniciativa se optó por contabilizar la cantidad de publicaciones\n",
    " por categoría, con la finalidad de verificar si se persibía una diferencia de\n",
    " magnitud o variabilidad entre ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "seaborn.countplot(data=df, x='category', color=\"salmon\")\n",
    "plt.xticks(rotation=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notar que no es el caso para este dataset teniendo entre 30600 a 36000 de\n",
    " cantidad por cada categoría. Algo también a recalcar es la presencia de\n",
    " títulos repetidos para algunas de estas como se muestra en la siguiente tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[category, title]].groupby(category).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Si bien la frecuencia de estas repeticiones no es alta (de a lo sumo 2\n",
    " repeticiones), se dan en una pequeña fracción de títulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Otro dato de interés es la proporción de publicaciones en español y portugués\n",
    " que se obtiene a través de la función `proportion` que determina este\n",
    " resultado agrupando por categorías. No obstante, tampoco se obtuvo una\n",
    " gran diferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_language_by_category = proportion(df, category, language).reset_index()\n",
    "fig = plt.figure(figsize=(15,7))\n",
    "seaborn.barplot(\n",
    "    y=df_language_by_category[\"count\"],\n",
    "    x=df_language_by_category[\"category\"],\n",
    "    hue=df_language_by_category[\"language\"],\n",
    "    ci=None\n",
    ")\n",
    "plt.xticks(rotation=70)\n",
    "plt.ylabel(\"Cantidad de publicaciones\")\n",
    "plt.xlabel(\"Categorías de publicaciones\")\n",
    "plt.ticklabel_format(style='plain', axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_language_by_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " También a partir de la siguiente tabla se puede observar la mínima y máxima\n",
    " proporción por categoría obteniendo que, de entre todas ellas, el idioma menos\n",
    " frecuente tiene al menos un 42% de las publicaciones. Las primeras 12 entre un\n",
    " 43% y un 57%. Y las restantes entre un 48% y un 53%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_language_by_category[[category, \"proportion\"]] \\\n",
    "    .groupby(category) \\\n",
    "    .agg(\n",
    "        min_proportion=(\"proportion\", \"min\"),\n",
    "        max_proportion=(\"proportion\", \"max\")\n",
    "    ).sort_values(by=\"min_proportion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Si se analiza para el total de publicaciones se obtiene que del total de\n",
    " 646760 publicaciones, 317768 (49.13%) son en español, 328992 (50.86%) son en\n",
    " portugués."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nof_items = len(df)\n",
    "nof_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nof_spanish_items = len(df[df[language] == \"spanish\"])\n",
    "(nof_spanish_items, nof_spanish_items / nof_items * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nof_portugues_items = nof_items - nof_spanish_items\n",
    "(nof_portugues_items, nof_portugues_items / nof_items * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Exploración de label quality\n",
    " Analogo al caso anterior, se analiza la proporción de publicaciones `reliable`\n",
    " y `unreliable` agrupando por categoría. A diferencia de los idiomas, hay gran\n",
    " disparidad en la calidad de las etiquetas siendo las menos confiables más\n",
    " abundantes. En particular, para ninguna categoría la proporción de `reliables`\n",
    " es mayor a 22.2945%. Otras categorías como `WINES` la cantidad de etiquetas\n",
    " confiables es incluso menor al 3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_by_category = proportion(df, category, label_quality).reset_index()\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "seaborn.barplot(\n",
    "    y=df_label_by_category[\"count\"],\n",
    "    x=df_label_by_category[\"category\"],\n",
    "    hue=df_label_by_category[\"label_quality\"],\n",
    "    ci=None\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ticklabel_format(style='plain', axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_by_category.sort_values(by=\"proportion\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Nuevamente para el total de publicaciones, solamente el 94882 (14.67%) son\n",
    " `reliable` y 551878 (85.32%) son `unreliable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nof_items = len(df)\n",
    "nof_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nof_reliable_labels = len(df[df[label_quality] == \"reliable\"])\n",
    "(nof_reliable_labels, nof_reliable_labels / nof_items * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nof_unreliable_labels = nof_items - nof_reliable_labels\n",
    "(nof_unreliable_labels, nof_unreliable_labels / nof_items * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Relación entre el label quality y el idioma\n",
    " La confiabilidad de las etiquetas podría deberse a si están en español o\n",
    " portugués, por ello se optó por calcular la proporción de estas pero agrupadas\n",
    " por idioma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_by_language = proportion(df, language, label_quality)\n",
    "df_label_by_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Las proporciones de `reliable` para portugués y para español son parecidas, de\n",
    " un 15% y un 13% respectivamente. Recordar además que del total de\n",
    " publicaciones el 14,67 % son `reliable`. Esto hace que pensar que hay\n",
    " independencia entre las variables `language` y `label_quality`. Si se toman\n",
    " los cantidades de la columna `count`, tenemos cuatro casos posibles:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    df[language],\n",
    "    df[label_quality]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Las variables aleatorias $X_{A}$ y $X_{B}$ asociadas a las poblaciones\n",
    " `language` y `label_quality` son independientes si para cada $x_{A} \\in\n",
    " \\{spanish, portugues\\}$ y $x_{B} \\in \\{reliable, unreliable\\}$ valores de\n",
    " ambas poblaciones, se tiene que:\n",
    "\n",
    " $P(X_{A}=x_{A}, X_{B}=x_{B}) =\n",
    " P(X_{A}=x_{A})P(X_{B}=x_{B})$\n",
    "\n",
    " A continuación, para cada uno de los cuatro casos se calcula el cociente entre\n",
    " esas probabilidades. Para ello, se considera la cantidad publicaciones en la muestra\n",
    " que adoptan el valor $x_A$, `nof_A`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nof_items = len(df)\n",
    "nof_A = df.groupby(language).size()\n",
    "nof_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Similarmente la cantidad de publicaciones que adoptan el valor $x_B$, `nof_B`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nof_B = df.groupby(label_quality).size()\n",
    "nof_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Luego aquellas que coinciden en $x_A$ y $x_B$, `nof_AB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nof_AB = df_label_by_language[\"count\"]\n",
    "nof_AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Luego se divide entre la cantidad de publicaciones para finalmente obtener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First divide between @nof_B and @nof_AB * nof_items so a dataframe of shape\n",
    "# @nof_AB is obtained\n",
    "nof_A * (nof_B / (nof_AB * nof_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Como los valores son todos muy cercanos a 1, se puede concluir que `language` y\n",
    " `label_quality` son independientes.\n",
    "\n",
    " Se hará un gráfico de barras, donde en lugar de mostrar el total de\n",
    " publicaciones para `reliable` y `unreliable` por idioma, se exhibirá la\n",
    " `proporción`, para español, para portugués, y para ambos idiomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nof_reliables = len(df[df[label_quality] ==\"reliable\"])\n",
    "nof_items = len(df)\n",
    "\n",
    "df_label_by_language = df_label_by_language.reset_index()\n",
    "cols = list(df_label_by_language.columns)\n",
    "\n",
    "both_reliable=[\n",
    "    \"both\",\n",
    "    \"reliable\",\n",
    "    nof_reliables,\n",
    "    nof_items,\n",
    "    nof_reliables/nof_items\n",
    "]\n",
    "both_unreliable=[\n",
    "    \"both\",\n",
    "    \"unreliable\",\n",
    "    nof_items - nof_reliables,\n",
    "    nof_items,\n",
    "    (nof_items - nof_reliables)/nof_items\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label_by_language = df_label_by_language.append(\n",
    "    {label:value for label, value in zip(cols, both_reliable)},\n",
    "    ignore_index=True\n",
    ")\n",
    "df_label_by_language = df_label_by_language.append(\n",
    "    {label:value for label, value in zip(cols, both_unreliable)},\n",
    "    ignore_index=True\n",
    ")\n",
    "df_label_by_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "seaborn.barplot(\n",
    "    y=df_label_by_language[\"proportion\"],\n",
    "    x=df_label_by_language[\"language\"],\n",
    "    hue=df_label_by_language[\"label_quality\"],\n",
    "    ci=None\n",
    ")\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylabel(\"Proporción Reliable vs Unreliable\")\n",
    "plt.xlabel(\"Idioma\")\n",
    "plt.ticklabel_format(style='plain', axis='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Exploración de la estructura de los títulos\n",
    " Para obtener una medida cuantitativa de la estructura que tiene el título de\n",
    " los articulos se optó por contabilizar por la cantidad de palabras, stopwords,\n",
    " dígitos, y caracteres especiales que aparecen en este por medio de las\n",
    " funciones `count_words`, `count_stopwords`, `count_digits`,\n",
    " `count_special_chars` aplicandose sobre cada item. (Puede tardar unos segundos\n",
    " debido al tamaño de la base de datos y a las operaciones que se realizan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_of_words = df[title] \\\n",
    "    .agg([\n",
    "        count_words,\n",
    "        count_stopwords,\n",
    "        count_digits,\n",
    "        count_special_chars\n",
    "    ]).join(df[[title, category]])\n",
    "df_analysis_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_of_words.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notar que se tiene en promedio un total de 7.52 palabras por título. En cuanto\n",
    " a stopwords, a pesar de ser recurrentes en textos como conectivos, este no fue\n",
    " el caso, probablemente debido a la necesidad de hacer énfasis en el item a\n",
    " vender en la menor cantidad de palabras posibles. De manera similar ocurre con\n",
    " la cantidad de caracteres especiales usados. Sin embargo, se dan algunos\n",
    " valores atípicos como el uso de 38 caracteres especiales en una publicación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Para conocer la cantidad de palabras con las que se cuenta por categoría se\n",
    " utiliza el data frame anterior para calcular el promedio de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis_of_words.groupby(category).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "seaborn.barplot(\n",
    "    data=df_analysis_of_words.groupby(category).mean().reset_index(),\n",
    "    x=category,\n",
    "    y=\"count_words\",\n",
    "    color=\"salmon\"\n",
    ")\n",
    "plt.xticks(rotation=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Nuevamente no hay una disparidad fuerte entre la cantidad de palabras usadas\n",
    " en el título por las categoría."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Para concluir el análisis se decidió considerar no solo la cantidad de\n",
    " palabras si no también la frecuencia en la que aparecen y si corresponden o\n",
    " tienen sentido con la categoría a la que fueron asociadas. Para ello, se\n",
    " remueven las stopwords, y los caracteres numéricos y especiales por medio de\n",
    " la función `remove_unimportant_words`. Luego para cada categoría se obtiene la\n",
    " frecuencia de todas las palabras que hayan aparecido en sus títulos para\n",
    " finalmente quedarse con las mejores 10. Algo a aclarar es que no se están\n",
    " aplicando técnicas de lematización al título si no que directamente se\n",
    " trabajan con su representación en minúsculas lo cual podría dar lugar a\n",
    " palabras que tienen una conjugación similar. Tampoco se está separando por\n",
    " palabras que correspondan solamente al español o al portugués llevando así a\n",
    " dar lugar a palabras frecuentes que tengan misma traducción. El siguiente data\n",
    " frame muestra estos resultados (La operación puede llevar unos\n",
    " segundos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_freq = df[title]\\\n",
    "    .apply(remove_unimportant_words) \\\n",
    "    .to_frame() \\\n",
    "    .join(df[category]) \\\n",
    "    .groupby(category) \\\n",
    "    .agg(\" \".join)[title] \\\n",
    "    .apply(lambda s: nltk.FreqDist(word_tokenize(s)).most_common(10)) \\\n",
    "    .to_frame() \\\n",
    "    .rename(columns={\"title\":\"top10_word_freq\"}) \\\n",
    "    .reset_index()\n",
    "df_word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Finalmente, si se elige alguna categoría en particular, por ejemplo\n",
    " `BABY_CAR_SEATS`, podemos obtener el siguiente gráfico de frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fdist = pd.Series(dict(\n",
    "    df_word_freq[\n",
    "        df_word_freq[\"category\"] == \"BABY_CAR_SEATS\"\n",
    "    ][\"top10_word_freq\"][0])\n",
    ")\n",
    "plt.figure(figsize=(20, 10))\n",
    "seaborn.barplot(\n",
    "    x=all_fdist.index,\n",
    "    y=all_fdist.values\n",
    ")\n",
    "plt.xticks(rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Claramente palabras como *auto*, *kg*, *butaca*, *bebe*, *huevito*, etc,\n",
    " corresponden con las esperadas para la compra de asientos para bebé con una\n",
    " frecuencia superior a las 4000 para las que aparecen en el gráfico. Por otro\n",
    " lado notar como unidades de medida tales como el *kg* son también útiles para\n",
    " este tipo de compras y que salieron a la vista dado por la eliminación de\n",
    " dígitos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
