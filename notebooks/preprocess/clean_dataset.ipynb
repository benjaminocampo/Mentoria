{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d533ac2a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    " # Categorización de publicaciones de productos de Mercado Libre\n",
    "\n",
    " Autores: Maximiliano Tejerina, Eduardo Barseghian, Benjamín Ocampo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd77195",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Funciones y Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d32e55",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import nltk\n",
    "from unidecode import unidecode\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import preprocessing\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b32a00",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "\n",
    "stopwords = \\\n",
    "    set(nltk.corpus.stopwords.words(\"spanish\")) | \\\n",
    "    set(nltk.corpus.stopwords.words(\"portuguese\"))\n",
    "\n",
    "\n",
    "def remove_unimportant_words(s):\n",
    "    \"\"\"\n",
    "    Removes from the string @s all the stopwords, digits, and special chars\n",
    "    \"\"\"\n",
    "    special_chars = \"-.+,[@_!#$%^&*()<>?/\\|}{~:]\"\n",
    "    digits = \"0123456789\"\n",
    "    invalid_chars = special_chars + digits\n",
    "\n",
    "    reduced_title = ''.join(c for c in s if not c in invalid_chars)\n",
    "\n",
    "    reduced_title = ' '.join(w.lower() for w in word_tokenize(reduced_title)\n",
    "                             if not w.lower() in stopwords)\n",
    "    return reduced_title\n",
    "\n",
    "\n",
    "def expand_contractions(s):\n",
    "    title = s\n",
    "    contractions = {\" c/u \": \"cada uno\", \" p/\": \"para\", \" c/\": \"con\"}\n",
    "    for key, value in contractions.items():\n",
    "        title = title.split(key)\n",
    "        title = value.join(title)\n",
    "    return title\n",
    "\n",
    "def prepare_tokenizer(words):\n",
    "    \"\"\"\n",
    "    funcion que genera un vocabulario, toma una lista de palabras.\n",
    "    retorna una lista de palabras tokenizadas.\n",
    "    \"\"\"\n",
    "    t = Tokenizer(filters='-.+,[@_!#$%^&*()<>?/\\|}{~:]0123456789', lower=True)\n",
    "    t.fit_on_texts(words)\n",
    "    encoded_docs = t.texts_to_sequences(words)\n",
    "    return pad_sequences(encoded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f218b498",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "URL = \"https://www.famaf.unc.edu.ar/~nocampo043/ml_challenge2019_dataset.csv\"\n",
    "df = pd.read_csv(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceefcc69",
   "metadata": {},
   "source": [
    "## Limpieza de Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab925a8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Tokenización y Secuencias\n",
    "TODO: Explicar que hace la función o como se realiza el encoding de los\n",
    "títulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa26f0fd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "encoded_titles = prepare_tokenizer(df.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb52df",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f6f129",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "encoded_labels = le.fit_transform(df[\"category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b5dfaf",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff3cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
